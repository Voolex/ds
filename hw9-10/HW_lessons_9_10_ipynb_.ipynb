{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_lessons_9-10.ipynb\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgxdX4L0dSw7"
      },
      "source": [
        "# Домашнее задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piodEhR7orUF"
      },
      "source": [
        "https://colab.research.google.com/drive/18HDckkUtYkRBwKh9uXSC44aRNDB8ahKA?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3_T-pcpnme8"
      },
      "source": [
        "**Дедлайн: 01.01.2021, 23:59**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2RmFtRDn5vy"
      },
      "source": [
        "Формат отчетности - jupyter notebook. Однако вычислять производные не обязательно в Markdown. Если вычисляете вручную, то дополнительно с ноутбуком, отправляйте pdf-файл с расписанным решением."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCDx6dKzeEhp"
      },
      "source": [
        "### Пример реализации градиентного спуска: https://github.com/ddvika/Data-Science-School-2020/blob/main/lecture_9/gradient_methods.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-G1btbwoStu"
      },
      "source": [
        "# Задания"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1XambpmoeIj"
      },
      "source": [
        "Перед выполнением ДЗ посмотрите на ноутбук, прикрепленный по ссылке выше. Там вы найдете реализацию градиентного спуска с постоянным и дробным шагом."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnSTXgrueAp0"
      },
      "source": [
        "### Задание 1. [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XmQ1AO9f1Qz"
      },
      "source": [
        "Релизуйте градиентный спуск с постоянным шагом и с дробным шагом для функции\n",
        "$$\n",
        "y = x_{1}^{2}+5 x_{2}^{2}\n",
        "$$\n",
        "\n",
        "в произвольно выбранной Вами точке."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAXdL_PDgYpS"
      },
      "source": [
        "Поэксперементируйте с разными значениями шага (скорости обучения), попробуйте хотя бы по 2-3 разных значения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBcNJ_Oupqq-"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM4IXqFEpt_1"
      },
      "source": [
        "def f(x):\r\n",
        "    return x[0]**2 + (5*(x[1]**2))\r\n",
        "    \r\n",
        "def grad_f(x):\r\n",
        "    return np.array([2*x[0], 10*x[1]])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xcqMUA3qISE"
      },
      "source": [
        "# С постоянным шагом\r\n",
        "\r\n",
        "def grad_descent_const_step(x = np.array([0, 0]), alpha = 0.001, epsilon = 0.05):\r\n",
        "    grad = grad_f(x)\r\n",
        "    n = 0\r\n",
        "    check = 0\r\n",
        "    while (np.linalg.norm(grad) > epsilon) or (check < 3):\r\n",
        "        x = x - alpha*grad\r\n",
        "        grad = grad_f(x)\r\n",
        "        n+=1\r\n",
        "        if (np.linalg.norm(grad) <= epsilon): check +=1\r\n",
        "    print(\"Градиентный спуск с постоянным шагом выполнил {} шагов\".format(n))\r\n",
        "    print(\"Точка с координатами х1 = {}, x2 = {}\".format(x[0], x[1]))\r\n",
        "    return x"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H8mBTM1qUa0",
        "outputId": "41046a86-39cc-4b65-92cc-9390a6eb351f"
      },
      "source": [
        "x = grad_descent_const_step(alpha = 0.001, x = [10,-20])\r\n",
        "print()\r\n",
        "x = grad_descent_const_step(alpha = 0.01, x = [10,-20])\r\n",
        "print()\r\n",
        "x = grad_descent_const_step(alpha = 0.1, x = [10,-20])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Градиентный спуск с постоянным шагом выполнил 2995 шагов\n",
            "Точка с координатами х1 = 0.024886920225562305, x2 = -1.6921459363215775e-12\n",
            "\n",
            "Градиентный спуск с постоянным шагом выполнил 299 шагов\n",
            "Точка с координатами х1 = 0.023801078244402314, x2 = -4.1642837864106503e-13\n",
            "\n",
            "Градиентный спуск с постоянным шагом выполнил 29 шагов\n",
            "Точка с координатами х1 = 0.015474250491067256, x2 = 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4mUuL5itgll"
      },
      "source": [
        "# С дробным шагом\r\n",
        "def grad_descent_step_splitting(x = np.array([0, 0]), alpha = 1, epsilon = 0.05, ksi = 0.5, lambda_d = 0.35):\r\n",
        "    grad = grad_f(x)\r\n",
        "    n = 0\r\n",
        "    n_alpha = 0\r\n",
        "    alpha_k = alpha\r\n",
        "    x_k0 = x\r\n",
        "    check = 0\r\n",
        "    while np.linalg.norm(grad) > epsilon or check < 3:\r\n",
        "        grad = grad_f(x_k0)\r\n",
        "        x_k1 = x_k0 - alpha_k*grad\r\n",
        "        while f(x_k1) - f(x_k0) > - alpha_k * ksi * (np.linalg.norm(grad)**2):\r\n",
        "            alpha_k *= lambda_d\r\n",
        "            x_k1 = x_k0 - alpha_k*grad\r\n",
        "            n_alpha+=1\r\n",
        "        x_k0 = x_k0 - alpha_k*grad\r\n",
        "        alpha_k = alpha\r\n",
        "        n+=1\r\n",
        "        if (np.linalg.norm(grad) <= epsilon): check +=1\r\n",
        "    x = x_k0\r\n",
        "    print(\"Градиентный спуст с дроблением шага выполнил {} шагов\".format(n))\r\n",
        "    print(\"Выполнено {} итераций дробления шага\".format(n_alpha))\r\n",
        "    print(\"Точка с координатами х1 = {}, x2 = {}\".format(x[0], x[1]))\r\n",
        "    return x"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbdQcBw1twIF",
        "outputId": "fe99c679-01e0-40a1-999b-d59768a04f6f"
      },
      "source": [
        "x = grad_descent_step_splitting(x = [10,-20])\r\n",
        "print()\r\n",
        "x = grad_descent_step_splitting(x = [10,-20], alpha = 10)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Градиентный спуст с дроблением шага выполнил 18 шагов\n",
            "Выполнено 36 итераций дробления шага\n",
            "Точка с координатами х1 = 0.0016387274618077752, x2 = 0.0007804071672653232\n",
            "\n",
            "Градиентный спуст с дроблением шага выполнил 20 шагов\n",
            "Выполнено 88 итераций дробления шага\n",
            "Точка с координатами х1 = 0.003853111936840591, x2 = -0.000496360691907724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucbvMBsdgOwV"
      },
      "source": [
        "### Задание 2. [3 points]\n",
        "\n",
        "Для функции из предыдущего задания реализуйте градиентный спуск, в котором значение шага (скорости обучения) будет изменяться по формуле циклического косинусного ожига. ( в англ. литературе - cosine annealing learning rate или cosine decay lr). \n",
        "\n",
        "Доп. литература:\n",
        "- Циклический косинусный отжиг https://habr.com/ru/post/332534/\n",
        "\n",
        "- Пример colise decay в библиотеке Pytorch:\n",
        "https://www.programmersought.com/article/12164650026/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ00AVJT1oL8"
      },
      "source": [
        "def cosine_decay_lr(alpha_prev, t, T, M):\r\n",
        "  return (alpha_prev/2) * (np.cos((np.pi * np.mod(t, T/M))/(T/M)) + 1)\r\n",
        "\r\n",
        "def grad_cos_dec_lr(x = x = np.array([0, 0]), alpha = 0.1, T = 50, M = 5):\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2Non6JiiVoJ"
      },
      "source": [
        "### Задание 3. [0.75 point]\n",
        "Проверьте работу Вашего градиентного спуска с косинусным отжигом на произвольной функции ( полином должен быть не меньше 3-ьего порядка и задан в пространстве не меньше $R^3$)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpONErtji81D"
      },
      "source": [
        "### Задание 4.\n",
        "Дана следующая плотность вероятности для случайной величины Х:\n",
        "$$\n",
        "f(x)=\\left\\{\\begin{array}{r}\n",
        "0 \\text { npu } x \\leq \\pi \\\\\n",
        "-\\cos x \\text { npu } \\pi<x \\leq \\frac{3}{2} \\pi \\\\\n",
        "\\text { 0 npu } x>\\frac{3}{2} \\pi\n",
        "\\end{array}\\right.\n",
        "$$\n",
        "\n",
        "1. Постройте график данной плотности вероятности **[0.25 point]**\n",
        "\n",
        "2. Определить вероятность попадания случайной величины X в интервал $\\left[\\pi, \\frac{5}{4} \\pi\\right]$ **[0.75 point]**\n",
        "\n",
        "3. Найти математическое ожидание и дисперсию случайной величины X . **[0.75 point]**\n",
        "\n",
        "Так как мы не проходили интегрирование, то в 2 и 3 пунктах можете использовать\n",
        "wolfram alpha (https://www.wolframalpha.com) для интегрирования. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LrqILMHkgTd"
      },
      "source": [
        "### Задание 5 [1.5 point]\n",
        "\n",
        " Случайная величина Х задана функцией распределения F(x).\n",
        "\n",
        " $$F(x)=\\left\\{\\begin{array}{c}0, x \\leq 1 \\\\ x-1,1<x \\leq 2 \\\\ 1, x>2\\end{array}\\right.$$\n",
        "\n",
        " 1. Является ли случайная величина Х непрерывной?\n",
        "\n",
        " 2. имеет ли случайная величина Х плотность вероятности f(X)? Если имеет, найти ее. \n",
        " 3. постройте графики f(X) и F(X), если такое возможно.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzQy9iYWmGD5"
      },
      "source": [
        "### Задание 6\n",
        "\n",
        "Рассмотрим несбалансированный набор данных с соотношением меньшего класса к большему 1: 100, где 100 экземпляров принадлежит меньшему классу, а 10 000 большему.\n",
        "\n",
        "Модель ML делает прогнозы и предсказывает 120 примеров как принадлежащих к классу меньшинства, 90 из которых верны, а 30 - неверны.\n",
        "\n",
        "Найти:\n",
        "\n",
        "- Precision **[0.5 point]**\n",
        "- Recall **[0.5 point]**\n",
        "- $F_1$ метрику **[0.5 point]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnkSjI5tdWJe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7a31985-9df5-4773-d415-a811d68f6158"
      },
      "source": [
        "print(f'Precision = {90/(90+30)}')\r\n",
        "print(f'Recall = {90/(90+10)}')\r\n",
        "print(f'F1 = {2 * 90/(90+30) * 90/(90+10) / (90/(90+30) + 90/(90+10))}')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision = 0.75\n",
            "Recall = 0.9\n",
            "F1 = 0.8181818181818182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mye_Q-jgdP0g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}